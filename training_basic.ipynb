{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1c0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531e149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ A pasta 'train' já contém arquivos. A extração foi abortada para evitar sobrescrita.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import extrair_zip_train_dir as zipService\n",
    "\n",
    "\n",
    "class ImageStitchingDatasetFiles(Dataset):\n",
    "    def __init__(self, folder_path, use_gradiente=False):\n",
    "        self.folder = Path(folder_path)\n",
    "        self.use_gradiente = use_gradiente\n",
    "        # Lista todos arquivos .pt ordenados\n",
    "        self.files = sorted(self.folder.glob(\"*.pt\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.load(self.files[idx])\n",
    "\n",
    "        def to_float_tensor(t):\n",
    "            # uint8 [0..255] -> float32 [0..1]\n",
    "            return t.float() / 255.0\n",
    "\n",
    "        parte1 = to_float_tensor(sample[\"parte1\"])\n",
    "        parte2 = to_float_tensor(sample[\"parte2\"])\n",
    "        groundtruth = to_float_tensor(sample[\"groundtruth\"])\n",
    "\n",
    "        if self.use_gradiente:\n",
    "            gradiente = to_float_tensor(sample[\"gradiente\"])\n",
    "            return (parte1, parte2), groundtruth, gradiente\n",
    "        else:\n",
    "            return (parte1, parte2), groundtruth\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"/home/prkd/.ssh/colab_key\"):\n",
    "    os.makedirs(\"/home/prkd/.ssh\", exist_ok=True)\n",
    "    print('Execute isso no terminal com a senha', \n",
    "          'scp prkdvps@64.71.153.122:/home/prkdvps/.ssh/colab_key ~/.ssh')\n",
    "\n",
    "else:\n",
    "    # Instala o sshfs\n",
    "    # !apt-get -qq install sshfs\n",
    "\n",
    "    # Cria diretórios locais\n",
    "    # !mkdir -p ./datasetzip ./logs ./checkpoints_epoch ./checkpoints_batch ./utils\n",
    "\n",
    "    # sshfs -o IdentityFile=/home/prkd/.ssh/colab_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null prkdvps@64.71.153.122:/home/prkdvps/datasetzip ./datasetzip\n",
    "    # sshfs -o IdentityFile=/home/prkd/.ssh/colab_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null prkdvps@64.71.153.122:/home/prkdvps/tensorboard/logs ./logs\n",
    "    # sshfs -o IdentityFile=/home/prkd/.ssh/colab_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null prkdvps@64.71.153.122:/home/prkdvps/tensorboard/checkpoints_epoch ./checkpoints_epoch\n",
    "    # sshfs -o IdentityFile=/home/prkd/.ssh/colab_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null prkdvps@64.71.153.122:/home/prkdvps/tensorboard/checkpoints_batch ./checkpoints_batch\n",
    "    # sshfs -o IdentityFile=/home/prkd/.ssh/colab_key -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null prkdvps@64.71.153.122:/home/prkdvps/utils ./utils\n",
    "\n",
    "    # !cp ./utils/metrics.py /content\n",
    "    # !cp ./utils/extrair_zip_train_dir.py /content\n",
    "\n",
    "    # !pip install pytorch-msssim\n",
    "    # !pip install lpips\n",
    "\n",
    "\n",
    "    filename = \"dataset_48_32.zip\"\n",
    "    # !mkdir -p ./datasetzip\n",
    "    # scp prkdvps@64.71.153.122:/home/prkdvps/datasetzip/dataset_48_32.zip ./datasetzip\n",
    "    # !rm -r ./train\n",
    "    # !mkdir -p ./train\n",
    "\n",
    "    zipService.descompactar_zip_com_progresso(f\"./{filename}\", \"./train\")\n",
    "    dataset = ImageStitchingDatasetFiles(\"./train\", use_gradiente=False)\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, prefetch_factor=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39e6bb",
   "metadata": {},
   "source": [
    "32 x 48\n",
    "| Bloco                    | Altura × Largura | Canais p/ encoder | Canais Pós-concatenação |\n",
    "|--------------------------|------------------|--------------------|--------------------------|\n",
    "| Entrada                  | 32×48            | 3                  | —                        |\n",
    "| `enc1`                   | 32×48            | 32                 | 64 (concat)              |\n",
    "| `pool1`                  | 16×24            | 32                 | 64 (concat)              |\n",
    "| `enc2`                   | 16×24            | 64                 | 128 (concat)             |\n",
    "| `pool2`                  | 8×12             | 64                 | 128 (concat)             |\n",
    "| Bottleneck (concat)      | 8×12             | —                  | 256                      |\n",
    "| `dec2` entrada           | 8×12             | 256 + 128 = 384    | —                        |\n",
    "| `dec2` saída             | 16×24            | 64                 | —                        |\n",
    "| `dec1` entrada           | 16×24            | 64 + 64 = 128      | —                        |\n",
    "| `dec1` saída             | 32×48            | 32                 | —                        |\n",
    "| Saída final              | 32×48            | 3                  | —                        |\n",
    "\n",
    "64x96\n",
    "| Bloco                    | Altura × Largura | Canais p/ encoder | Canais Pós-concatenação |\n",
    "|--------------------------|------------------|--------------------|--------------------------|\n",
    "| Entrada                  | 64×96            | 3                  | —                        |\n",
    "| `enc1`                   | 64×96            | 32                 | 64 (concat)              |\n",
    "| `pool1`                  | 32×48            | 32                 | 64 (concat)              |\n",
    "| `enc2`                   | 32×48            | 64                 | 128 (concat)             |\n",
    "| `pool2`                  | 16×24            | 64                 | 128 (concat)             |\n",
    "| Bottleneck (concat)      | 16×24            | —                  | 256                      |\n",
    "| `dec2` entrada           | 16×24            | 256 + 128 = 384    | —                        |\n",
    "| `dec2` saída             | 32×48            | 64                 | —                        |\n",
    "| `dec1` entrada           | 32×48            | 64 + 64 = 128      | —                        |\n",
    "| `dec1` saída             | 64×96            | 32                 | —                        |\n",
    "| Saída final              | 64×96            | 3                  | —                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119f9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CBAM (Convolutional Block Attention Module)\n",
    "# Aplica atenção canal + espacial separadamente\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "        self.conv_spatial = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Atenção no canal\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        x_out = x * self.sigmoid_channel(avg_out + max_out)  # salva num novo tensor para não perder o input original\n",
    "\n",
    "        # Atenção espacial\n",
    "        avg_out = torch.mean(x_out, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x_out, dim=1, keepdim=True)\n",
    "        spatial_attention = torch.cat([avg_out, max_out], dim=1)  # [N, 2, H, W]\n",
    "        spatial_attention = self.sigmoid_spatial(self.conv_spatial(spatial_attention))  # [N, 1, H, W]\n",
    "\n",
    "        # Multiplica o resultado da atenção espacial pelo tensor original (com canais corretos)\n",
    "        out = x_out * spatial_attention\n",
    "\n",
    "        return out\n",
    "\n",
    "# Self-Attention simples no bottleneck\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.key = nn.Conv2d(in_dim, in_dim // 8, 1)\n",
    "        self.value = nn.Conv2d(in_dim, in_dim, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        proj_query = self.query(x).view(B, -1, H * W).permute(0, 2, 1)\n",
    "        proj_key = self.key(x).view(B, -1, H * W)\n",
    "        energy = torch.bmm(proj_query, proj_key)  # matriz de atenção\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "\n",
    "        proj_value = self.value(x).view(B, -1, H * W)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(B, C, H, W)\n",
    "        return self.gamma * out + x\n",
    "\n",
    "# Bloco de codificação padrão\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Bloco de decodificação com upsample + concat + convoluções\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_skip, ch_out):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(ch_in, ch_out, kernel_size=2, stride=2)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out + ch_skip, ch_out, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, 3, padding=1),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        if x.shape[2:] != skip.shape[2:]:\n",
    "            x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "# Rede UNet com dois encoders, CBAM e self-attention no bottleneck\n",
    "class DualEncoderUNet_CBAM_SA_Small(nn.Module):\n",
    "    def __init__(self, in_channels=3, base_ch=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dois encoders independentes (parte1 e parte2)\n",
    "        self.enc1_1 = EncoderBlock(in_channels, base_ch)\n",
    "        self.enc2_1 = EncoderBlock(base_ch, base_ch * 2)\n",
    "\n",
    "        self.enc1_2 = EncoderBlock(in_channels, base_ch)\n",
    "        self.enc2_2 = EncoderBlock(base_ch, base_ch * 2)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck com self-attention\n",
    "        self.bottleneck = EncoderBlock(base_ch * 4, base_ch * 4)\n",
    "        self.attn = SelfAttention(base_ch * 4)\n",
    "\n",
    "        # CBAM nas skip connections\n",
    "        self.cbam2 = CBAM(base_ch * 4)\n",
    "        self.cbam1 = CBAM(base_ch * 2)\n",
    "\n",
    "        # Decoder com três parâmetros por bloco\n",
    "        self.dec2 = DecoderBlock(base_ch * 4, base_ch * 4, base_ch * 2)  # 128, 128, 64\n",
    "        self.dec1 = DecoderBlock(base_ch * 2, base_ch * 2, base_ch)      # 64, 64, 32\n",
    "\n",
    "        self.final = nn.Conv2d(base_ch, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Encoder para parte1\n",
    "        e1_1 = self.enc1_1(x1)\n",
    "        e2_1 = self.enc2_1(self.pool(e1_1))\n",
    "\n",
    "        # Encoder para parte2\n",
    "        e1_2 = self.enc1_2(x2)\n",
    "        e2_2 = self.enc2_2(self.pool(e1_2))\n",
    "\n",
    "        # Garantir que as features estejam com mesmas dimensões (por segurança)\n",
    "        if e1_1.shape[2:] != e1_2.shape[2:]:\n",
    "            e1_2 = F.interpolate(e1_2, size=e1_1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        if e2_1.shape[2:] != e2_2.shape[2:]:\n",
    "            e2_2 = F.interpolate(e2_2, size=e2_1.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Bottleneck: concatenação + atenção\n",
    "        b = self.bottleneck(torch.cat([self.pool(e2_1), self.pool(e2_2)], dim=1))\n",
    "        b = self.attn(b)\n",
    "\n",
    "        if debug > 0: print(\"b shape:\", b.shape)\n",
    "        if debug > 0: print(\"skip2 shape:\", self.cbam2(torch.cat([e2_1, e2_2], dim=1)).shape)\n",
    "        if debug > 0: print(\"skip1 shape:\", self.cbam1(torch.cat([e1_1, e1_2], dim=1)).shape)\n",
    "\n",
    "\n",
    "        # Decoder com CBAM nas skip connections\n",
    "        d2 = self.dec2(b, self.cbam2(torch.cat([e2_1, e2_2], dim=1)))\n",
    "        d1 = self.dec1(d2, self.cbam1(torch.cat([e1_1, e1_2], dim=1)))\n",
    "\n",
    "        return torch.sigmoid(self.final(d1))  # saída com valo\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=9):  # Agora espera parte1 (3) + parte2 (3) + target/fake (3)\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_feat))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(in_channels, 64, normalize=False),  # in_channels = 9\n",
    "            *block(64, 128),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, padding=1)  # saída do PatchGAN (mapa de decisão)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d415f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prkd/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/prkd/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/prkd/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_msssim import ssim, ms_ssim\n",
    "import lpips\n",
    "from metrics import compute_all_metrics  # Importa a função de métricas do arquivo metrics.py\n",
    "from tqdm import tqdm\n",
    "\n",
    "debug = 0\n",
    "# from generator import DualEncoderUNet_CBAM_SA_Small  # novo gerador com 2 encoders, CBAM e SelfAttention\n",
    "# from discriminator import PatchDiscriminator  # ou caminho equivalente\n",
    "\n",
    "# LPIPS usa um modelo de rede para comparação perceptual\n",
    "lpips_fn = lpips.LPIPS(net='alex')\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def carregar_checkpoint_mais_recente(checkpoints_epoch_dir, checkpoints_batch_dir):\n",
    "    \"\"\"\n",
    "    Retorna o caminho, epoch e batch do checkpoint mais recente (epoch ou batch).\n",
    "    \n",
    "    Returns:\n",
    "        (str caminho, int epoch, int batch)\n",
    "        batch = -1 significa checkpoint de final de epoch\n",
    "    \"\"\"\n",
    "    pattern_epoch = re.compile(r\"checkpoint_epoch(\\d+)\\.pt\")\n",
    "    pattern_batch = re.compile(r\"checkpoint_epoch(\\d+)_batch(\\d+)\\.pt\")\n",
    "\n",
    "    def extract_epoch_batch(filename):\n",
    "        match = pattern_batch.match(filename)\n",
    "        if match:\n",
    "            return int(match.group(1)), int(match.group(2)), filename\n",
    "        match = pattern_epoch.match(filename)\n",
    "        if match:\n",
    "            return int(match.group(1)), -1, filename\n",
    "        return None\n",
    "\n",
    "    all_checkpoints = []\n",
    "\n",
    "    for fname in os.listdir(checkpoints_epoch_dir):\n",
    "        result = extract_epoch_batch(fname)\n",
    "        if result:\n",
    "            epoch, batch, name = result\n",
    "            all_checkpoints.append((epoch, batch, os.path.join(checkpoints_epoch_dir, name)))\n",
    "\n",
    "    for fname in os.listdir(checkpoints_batch_dir):\n",
    "        result = extract_epoch_batch(fname)\n",
    "        if result:\n",
    "            epoch, batch, name = result\n",
    "            all_checkpoints.append((epoch, batch, os.path.join(checkpoints_batch_dir, name)))\n",
    "\n",
    "    if not all_checkpoints:\n",
    "        return None, 0, -1  # Nada encontrado\n",
    "\n",
    "    # Ordena por (epoch, batch)\n",
    "    all_checkpoints.sort(key=lambda x: (x[0], x[1]))\n",
    "    epoch, batch, path = all_checkpoints[-1]\n",
    "    return path, epoch, batch\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "    generator, discriminator, dataloader, device, epochs,\n",
    "    save_every, checkpoint_dir, checkpoint_batch_dir,\n",
    "    tensorboard_dir, metrics, lr_g=2e-4, lr_d=2e-4,\n",
    "    lr_min=1e-6, gen_steps_per_batch=1\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(checkpoint_batch_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(tensorboard_dir)\n",
    "\n",
    "    criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "    scheduler_G = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_G, T_max=epochs, eta_min=lr_min)\n",
    "    scheduler_D = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_D, T_max=epochs, eta_min=lr_min)\n",
    "\n",
    "    start_epoch = 0\n",
    "    # checkpoint_path = carregar_checkpoint_mais_recente(checkpoint_dir, checkpoint_batch_dir)\n",
    "    checkpoint_path, start_epoch, start_batch = carregar_checkpoint_mais_recente(\"checkpoints_epoch\", \"checkpoints_batch\")\n",
    "\n",
    "    if checkpoint_path:\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "            optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "            optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
    "            # ... quaisquer outras coisas\n",
    "\n",
    "            # ⚠️ Ajuste aqui: para continuar da mesma epoch\n",
    "            # start_epoch permanece igual se batch != -1\n",
    "            if start_batch == -1:\n",
    "                start_epoch += 1\n",
    "                start_batch = 0\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        start_batch = 0\n",
    "\n",
    "    last_checkpoint_time = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for i, ((part1, part2), target) in pbar:\n",
    "\n",
    "            # Se estiver retomando a primeira epoch, pule os batches anteriores\n",
    "            if epoch == start_epoch and i < start_batch:\n",
    "                continue\n",
    "            \n",
    "            part1 = part1.to(device)\n",
    "            part2 = part2.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            real_input = torch.cat([part1, part2, target], dim=1)\n",
    "            fake = generator(part1, part2)\n",
    "            fake_input = torch.cat([part1, part2, fake.detach()], dim=1)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            pred_real = discriminator(real_input)\n",
    "            pred_fake = discriminator(fake_input)\n",
    "\n",
    "            loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real))\n",
    "            loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake))\n",
    "            loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train Generator\n",
    "            for _ in range(gen_steps_per_batch):\n",
    "                fake = generator(part1, part2)\n",
    "                fake_input = torch.cat([part1, part2, fake], dim=1)\n",
    "                optimizer_G.zero_grad()\n",
    "                pred_fake = discriminator(fake_input)\n",
    "                loss_G_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake))\n",
    "                loss_G_L1 = criterion_L1(fake, target)\n",
    "                loss_G = 8.0 * loss_G_GAN + 2.0 * loss_G_L1\n",
    "                loss_G.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"loss_G\": f\"{loss_G.item():.4f}\",\n",
    "                \"loss_D\": f\"{loss_D.item():.4f}\"\n",
    "            })\n",
    "\n",
    "            writer.add_scalar(\"Loss/Generator\", loss_G.item(), epoch * len(dataloader) + i)\n",
    "            writer.add_scalar(\"Loss/Discriminator\", loss_D.item(), epoch * len(dataloader) + i)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                eval_metrics = compute_all_metrics(fake, target, part1, part2, writer, epoch * len(dataloader) + i)\n",
    "                for k, v in eval_metrics.items():\n",
    "                    if v is not None:\n",
    "                        writer.add_scalar(f\"Metrics/{k}\", v, epoch * len(dataloader) + i)\n",
    "\n",
    "            # Checkpoint a cada 10 minutos\n",
    "            if time.time() - last_checkpoint_time > 600:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'batch': i,\n",
    "                    'generator_state_dict': generator.state_dict(),\n",
    "                    'discriminator_state_dict': discriminator.state_dict(),\n",
    "                    'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                    'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                }, os.path.join(checkpoint_batch_dir, f'checkpoint_epoch{epoch}_batch{i}.pt'))\n",
    "                last_checkpoint_time = time.time()\n",
    "\n",
    "        # Fim da época: salvar checkpoint principal\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "        }, os.path.join(checkpoint_dir, f'checkpoint_epoch{epoch}.pt'))\n",
    "\n",
    "        scheduler_G.step()\n",
    "        scheduler_D.step()\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd0828f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retomando de checkpoint: checkpoints_batch/checkpoint_epoch0_batch131.pt (epoch=0, batch=131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 1/660 [00:00<09:45,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   0%|          | 2/660 [00:01<06:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   1%|          | 4/660 [00:01<03:24,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 2\n",
      "0 131 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   1%|          | 5/660 [00:01<02:48,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   1%|          | 7/660 [00:02<02:42,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 5\n",
      "0 131 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   1%|▏         | 9/660 [00:02<02:45,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 7\n",
      "0 131 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   2%|▏         | 10/660 [00:03<03:18,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 9\n",
      "0 131 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   2%|▏         | 12/660 [00:03<02:43,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 11\n",
      "0 131 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   2%|▏         | 15/660 [00:04<02:33,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 13\n",
      "0 131 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   2%|▏         | 16/660 [00:05<04:12,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 15\n",
      "0 131 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   3%|▎         | 19/660 [00:05<03:14,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 17\n",
      "0 131 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   3%|▎         | 20/660 [00:06<03:06,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 19\n",
      "0 131 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   3%|▎         | 23/660 [00:06<02:32,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 21\n",
      "0 131 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   4%|▎         | 24/660 [00:07<02:31,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 23\n",
      "0 131 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   4%|▍         | 26/660 [00:07<02:59,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   4%|▍         | 28/660 [00:08<02:39,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 26\n",
      "0 131 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   4%|▍         | 29/660 [00:08<02:15,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   5%|▍         | 30/660 [00:08<02:32,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   5%|▍         | 31/660 [00:09<02:59,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 30\n",
      "0 131 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   5%|▌         | 33/660 [00:09<02:15,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   5%|▌         | 34/660 [00:09<02:43,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   5%|▌         | 35/660 [00:10<03:02,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 34\n",
      "0 131 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   6%|▌         | 37/660 [00:10<02:17,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   6%|▌         | 38/660 [00:10<02:28,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   6%|▌         | 39/660 [00:10<02:42,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 38\n",
      "0 131 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   6%|▌         | 41/660 [00:11<02:05,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   6%|▋         | 42/660 [00:11<02:27,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   7%|▋         | 45/660 [00:12<01:55,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 42\n",
      "0 131 43\n",
      "0 131 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   7%|▋         | 46/660 [00:12<01:59,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   7%|▋         | 47/660 [00:12<02:57,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 46\n",
      "0 131 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   7%|▋         | 49/660 [00:13<02:17,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:   8%|▊         | 50/660 [00:13<02:44,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 131 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m generator \u001b[38;5;241m=\u001b[39m DualEncoderUNet_CBAM_SA_Small()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m PatchDiscriminator()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoints_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_batch_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoints_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtensorboard_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs/32x48\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_steps_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 112\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, dataloader, device, epochs, save_every, checkpoint_dir, checkpoint_batch_dir, tensorboard_dir, metrics, lr_g, lr_d, lr_min, gen_steps_per_batch)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs):\n\u001b[1;32m    111\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ((part1, part2), target) \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mprint\u001b[39m(start_epoch, start_batch, i)\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m# Se estiver retomando a primeira epoch, pule os batches anteriores\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1443\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1445\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/ImageStitching/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"torch\")\n",
    "\n",
    "debug = 0\n",
    "\n",
    "# Hiperparâmetros\n",
    "num_epochs = 100\n",
    "gen_steps_per_batch = 20\n",
    "learning_rate = 2e-4\n",
    "lr_min = 1e-5\n",
    "lr_max = 2e-4\n",
    "log_interval = 600  # em segundos (10 minutos)\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Exemplo de chamada (fora do train.py):\n",
    "generator = DualEncoderUNet_CBAM_SA_Small().to(device)\n",
    "discriminator = PatchDiscriminator().to(device)\n",
    "train(generator, discriminator, dataloader, device, epochs=200, save_every=600,\n",
    "      checkpoint_dir=\"./checkpoints_epoch\", checkpoint_batch_dir=\"./checkpoints_batch\",\n",
    "      tensorboard_dir=\"./logs/32x48\", metrics=True, gen_steps_per_batch=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizar_amostra_pt(caminho_pt):\n",
    "    \"\"\"\n",
    "    Visualiza a amostra salva no arquivo .pt no formato esperado:\n",
    "    dicionário com chaves: 'parte1', 'parte2', 'mask', 'groundtruth', 'gradiente'.\n",
    "    Cada tensor é uint8, shape [C, H, W].\n",
    "\n",
    "    Parâmetros:\n",
    "        caminho_pt (str ou Path): caminho do arquivo .pt a ser aberto\n",
    "    \"\"\"\n",
    "    sample = torch.load(caminho_pt)\n",
    "\n",
    "    print(\"Chaves no arquivo:\", list(sample.keys()))\n",
    "    for k, v in sample.items():\n",
    "        print(f\"{k}: shape {v.shape}, dtype {v.dtype}\")\n",
    "\n",
    "    # Converter para formato H x W x C e mostrar com matplotlib\n",
    "    def tensor_to_img(tensor):\n",
    "        # tensor [C, H, W], uint8\n",
    "        img = tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        return img\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    for i, key in enumerate(['parte1', 'parte2', 'mask', 'groundtruth', 'gradiente'], 1):\n",
    "        if key in sample:\n",
    "            img = tensor_to_img(sample[key])\n",
    "            shape_str = sample[key].shape\n",
    "            plt.subplot(2, 3, i)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"{key} - {shape_str}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualizar_amostra_pt(\"./train/000000009286_sample10.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9234ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔐 Variáveis com o conteúdo da chave pública e privada\n",
    "PRIVATE_KEY = \"\"\"\n",
    "-----BEGIN OPENSSH PRIVATE KEY-----\n",
    "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
    "QyNTUxOQAAACDhMdKyaW9Q6h7gbSNiEccuYXUrUS9PekHNCwnSdKkliwAAAJBX9BMSV/QT\n",
    "EgAAAAtzc2gtZWQyNTUxOQAAACDhMdKyaW9Q6h7gbSNiEccuYXUrUS9PekHNCwnSdKkliw\n",
    "AAAEACeDr6P/5M1e73MfCFezLbib6MTEvwrqYGLqxMMQB/dOEx0rJpb1DqHuBtI2IRxy5h\n",
    "dStRL096Qc0LCdJ0qSWLAAAADGNvbGFiLWFjY2VzcwE=\n",
    "-----END OPENSSH PRIVATE KEY-----\n",
    "\"\"\"\n",
    "\n",
    "PUBLIC_KEY = \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOEx0rJpb1DqHuBtI2IRxy5hdStRL096Qc0LCdJ0qSWL colab-access\"\n",
    "\n",
    "REMOTE_USER = \"prkdvps\"\n",
    "REMOTE_HOST = \"64.71.153.122\"\n",
    "KEY_PATH = \"/root/.ssh/colab_key\"\n",
    "\n",
    "import os\n",
    "\n",
    "# Criação da pasta .ssh\n",
    "os.makedirs(\"/root/.ssh\", exist_ok=True)\n",
    "\n",
    "# Escreve chave privada\n",
    "with open(KEY_PATH, \"w\") as f:\n",
    "    f.write(PRIVATE_KEY.strip())\n",
    "\n",
    "# Escreve chave pública\n",
    "with open(\"/root/.ssh/colab_key.pub\", \"w\") as f:\n",
    "    f.write(PUBLIC_KEY.strip())\n",
    "\n",
    "# Ajusta permissões\n",
    "!chmod 600 /root/.ssh/colab_key\n",
    "!chmod 644 /root/.ssh/colab_key.pub\n",
    "\n",
    "# Adiciona o host remoto no known_hosts\n",
    "!ssh-keyscan -H $REMOTE_HOST >> /root/.ssh/known_hosts\n",
    "\n",
    "# Instala o sshfs\n",
    "!apt-get -qq install sshfs > /dev/null\n",
    "\n",
    "# Cria diretórios locais\n",
    "!mkdir -p ./datasetzip ./logs ./checkpoints_epoch ./checkpoints_batch ./utils\n",
    "\n",
    "!sshfs -o IdentityFile=~/.ssh/colab_key prkdvps@64.71.153.122:/home/prkdvps/datasetzip ./datasetzip\n",
    "!sshfs -o IdentityFile=~/.ssh/colab_key prkdvps@64.71.153.122:/home/prkdvps/tensorboard/logs ./logs\n",
    "!sshfs -o IdentityFile=~/.ssh/colab_key prkdvps@64.71.153.122:/home/prkdvps/tensorboard/checkpoints_epoch ./checkpoints_epoch\n",
    "!sshfs -o IdentityFile=~/.ssh/colab_key prkdvps@64.71.153.122:/home/prkdvps/tensorboard/checkpoints_batch ./checkpoints_batch\n",
    "!sshfs -o IdentityFile=~/.ssh/colab_key prkdvps@64.71.153.122:/home/prkdvps/utils ./utils\n",
    "\n",
    "!cp ./utils/metrics.py /content\n",
    "!cp ./utils/extrair_zip_train_dir.py /content\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageStitching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
